{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf ### models\n",
    "import numpy as np\n",
    "import pandas as pd ### reading and procesing data\n",
    "import seaborn as sns ### visualizacion\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import pydot as pydot\n",
    "import tensorflow_datasets as tfds\n",
    "from plot_model import plot_model\n",
    "from tensorflow.keras.layers import Normalization, Dense, InputLayer, Dropout, Conv2D, MaxPool2D, Flatten, BatchNormalization \n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError, MeanAbsolutePercentageError\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#DEFINIMOS LA TAREA:\n",
    "\n",
    "En este caso crearemos un modelo para clasificar si una celula posee malaria o no. Para ello utilizaremos una red neuronal convolucional.\n",
    "La malaria es una enfermedad causada por un parásito Plasmodium, el cual es trasmitido por la picadura de un mosquito infectado. \n",
    "Sólo el género anófeles del mosquito transmite la malaria. Los síntomas de esta enfermedad pueden incluir fiebre, vómito y/o dolor de cabeza.\n",
    "Las muestras de sangre son examinadas con un microscopio para diagnosticar la malaria, en donde el parásito es detectado dentro de los glóbulos rojos.\n",
    "Ante esto estamos frente a una clasificacion binaria ya que nuestro paciente solo podra tener la enfermedad o no tenerla\n",
    "\n",
    "En las muestras de las celulas nos daremos cuenta si estas estan infectadas por el color. \n",
    "Utilizamos una imagen, de una determinada cantidad de pixeles. Estaremos haciendo una clasificacion de imagenes.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DATA PREPARATION:\n",
    "\n",
    "El conjunto de datos de Malaria contiene un total de 27.558 imágenes de células con instancias iguales de células parasitadas y no infectadas \n",
    "de las imágenes de diapositivas de frotis de sangre delgada de células segmentadas.\n",
    "La altura de pixeles varia un poco, por lo que no tienen todas las imagenes la misma cantidad de pixeles.\n",
    "\"\"\"\n",
    "\n",
    "dataset, dataset_info = tfds.load('malaria', with_info = True, as_supervised=True, shuffle_files=True, split=['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(dataset, TRAIN_RATIO, VAL_RATIO):\n",
    "    DATA_SIZE = len(dataset)\n",
    "    #TRAIN SET\n",
    "    train_dataset = dataset.take(int(TRAIN_RATIO*DATA_SIZE))\n",
    "\n",
    "    #VAL SET\n",
    "    val_test_dataset = dataset.skip(int(TRAIN_RATIO*DATA_SIZE))\n",
    "    val_dataset = dataset.take(int(TRAIN_RATIO*DATA_SIZE))\n",
    "\n",
    "    #TEST SET\n",
    "    test_dataset = val_test_dataset.skip(int(TRAIN_RATIO*DATA_SIZE))\n",
    "\n",
    "    return train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_RATIO = 0.8\n",
    "VAL_RATIO = 0.1\n",
    "TEST_RATIO = 0.1\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = split(dataset[0], TRAIN_RATIO, VAL_RATIO)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"VISUALIZACION\"\"\"\n",
    "for i, (image,label) in enumerate(train_dataset.take(16)):\n",
    "    ax = plt.subplot(4,4,i+1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(dataset_info.features['label'].int2str(label))\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IM_SIZE = 224\n",
    "def resize_rescale(image, label):\n",
    "    return tf.image.resize(image, (IM_SIZE, IM_SIZE))/255.0, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DATA PROCESSING\n",
    "\n",
    "Vamos a procesar el tamaño de nuestras imagenes para luego normalizarlo\n",
    "En nuestro caso normalizaremos a 224x224 pero en algunos casos se puede estandarizar el tamaño de los pixeles.\n",
    "\"\"\"\n",
    "\n",
    "train_dataset = train_dataset.map(resize_rescale)\n",
    "val_dataset = val_dataset.map(resize_rescale)\n",
    "test_dataset = test_dataset.map(resize_rescale)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataset = train_dataset.shuffle(buffer_size=8, reshuffle_each_iteration=True).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "val_dataset = val_dataset.shuffle(buffer_size=8, reshuffle_each_iteration=True).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(1)\n",
    "#No nos hace falta hacerlo para el test set ya que no necesitamos mezclarlo ni premezclarlo, pero si para el train y el validation set.\n",
    "#Esto se hace para que tengan las mismas dimensiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Para este ejercicio utilizaremos redes neuronales convulcionales o CNN. Las CNN se utilizan para el procesar imagenes.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet_model = keras.Sequential([\n",
    "    InputLayer(shape = (IM_SIZE, IM_SIZE, 3)),\n",
    "\n",
    "    Conv2D(filters = 6, kernel_size = 3, strides = 1, padding = 'valid', activation = 'relu'),\n",
    "    BatchNormalization(), #Normalizamos estandarizando -> (X - Media) \\ desviacion estandar\n",
    "    MaxPool2D(pool_size=2, strides=2),\n",
    "\n",
    "    Conv2D(filters = 16, kernel_size = 3, strides = 1, padding = 'valid', activation = 'relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPool2D(pool_size=2, strides=2), #Max pool usa el valor maximo del pool en cuestion\n",
    "\n",
    "    Flatten(),\n",
    "\n",
    "    Dense(100, activation = 'relu'),\n",
    "    BatchNormalization(),\n",
    "    Dense(10, activation = 'relu'),\n",
    "    BatchNormalization(),\n",
    "    Dense(1, activation = 'sigmoid'), #Solo tenemos un output ya que puede estar o no infectada\n",
    "\n",
    "])\n",
    "\n",
    "lenet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compilamos nuestro modelo\n",
    "lenet_model.compile(\n",
    "    optimizer= Adam(learning_rate=0.01),\n",
    "    loss = BinaryCrossentropy(),\n",
    "    metrics = 'accuracy' #Nos mostrara la precision del modelo\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrenamos nuestro modelo\n",
    "history = lenet_model.fit(train_dataset, validation_data=val_dataset, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train_loss', 'val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train_accuracy', 'val_accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet_model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parasite_or_not(x):\n",
    "    if (x<0.5):\n",
    "        return str('P')\n",
    "    else:\n",
    "        return str('U')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (image, label) in enumerate(test_dataset.take(9)):\n",
    "    ax = plt.subplot(3,3,i+1)\n",
    "    plt.imshow(image[0])\n",
    "    plt.title(str(parasite_or_not(label.numpy()[0]) + \":\" + str(parasite_or_not(lenet_model.predict(image)[0][0]))))\n",
    "\n",
    "    plt.axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
